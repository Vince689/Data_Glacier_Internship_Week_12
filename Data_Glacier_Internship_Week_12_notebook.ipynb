{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "79bad04e",
   "metadata": {},
   "source": [
    "<font color=\"purple\" size=\"4px\"> This is the modelling component of the final project for the internship with Data Glacier. We will explore various models. ROC-AUC will be used as the main scoring metric, since the classes in the target are somewhat imbalanced </font>. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c7d0f02",
   "metadata": {},
   "source": [
    "<font color=\"purple\" size=\"4px\"> Let's begin by importing each dataset, shuffling and defining new dataframes: </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dce534ca",
   "metadata": {},
   "source": [
    "Import, shuffle and reset index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a6bff5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df_modified=pd.read_csv(r'df_modified.csv', engine='python').sample(frac=1).reset_index(drop=True) #cleaned dataset, with some rows (with outliers) removed\n",
    "df_modified2= pd.read_csv(r'df_modified_all_rows.csv', engine='python').sample(frac=1).reset_index(drop=True) #cleaned dataset but without rows (with outliers) removed - has been created for the modelling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "27b20e77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1215, 115) (3424, 115)\n"
     ]
    }
   ],
   "source": [
    "print(df_modified.shape,df_modified2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce0fb6ca",
   "metadata": {},
   "source": [
    "Let's create a dataframes with the 6 best features (found in weeks 8-9) and the target variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4d9f900c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_best = [df_modified[\"Dexa_During_Rx_Y\"] , df_modified[\"Comorb_Encounter_For_Screening_For_Malignant_Neoplasms_Y\"], df_modified[\"Comorb_Encounter_For_Immunization_Y\"] , df_modified[\"Comorb_Encntr_For_General_Exam_W_O_Complaint,_Susp_Or_Reprtd_Dx_Y\"] , df_modified[\"Comorb_Long_Term_Current_Drug_Therapy_Y\"] , df_modified[\"Concom_Viral_Vaccines_Y\"], df_modified[\"Persistency_Flag_Persistent\"]]\n",
    "headers = [\"Dexa_During_Rx_Y\" , \"Comorb_Encounter_For_Screening_For_Malignant_Neoplasms_Y\", \"Comorb_Encounter_For_Immunization_Y\" ,\"Comorb_Encntr_For_General_Exam_W_O_Complaint,_Susp_Or_Reprtd_Dx_Y\" , \"Comorb_Long_Term_Current_Drug_Therapy_Y\" , \"Concom_Viral_Vaccines_Y\", \"Persistency_Flag_Persistent\"]\n",
    "df_best=pd.concat(data_best, axis=1, keys=headers)\n",
    "\n",
    "data_best2 = [df_modified2[\"Dexa_During_Rx_Y\"] , df_modified2[\"Comorb_Encounter_For_Screening_For_Malignant_Neoplasms_Y\"], df_modified2[\"Comorb_Encounter_For_Immunization_Y\"] , df_modified2[\"Comorb_Encntr_For_General_Exam_W_O_Complaint,_Susp_Or_Reprtd_Dx_Y\"] , df_modified2[\"Comorb_Long_Term_Current_Drug_Therapy_Y\"] , df_modified2[\"Concom_Viral_Vaccines_Y\"], df_modified2[\"Persistency_Flag_Persistent\"]]\n",
    "headers = [\"Dexa_During_Rx_Y\" , \"Comorb_Encounter_For_Screening_For_Malignant_Neoplasms_Y\", \"Comorb_Encounter_For_Immunization_Y\" ,\"Comorb_Encntr_For_General_Exam_W_O_Complaint,_Susp_Or_Reprtd_Dx_Y\" , \"Comorb_Long_Term_Current_Drug_Therapy_Y\" , \"Concom_Viral_Vaccines_Y\", \"Persistency_Flag_Persistent\"]\n",
    "df_best2=pd.concat(data_best2, axis=1, keys=headers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46ae98ae",
   "metadata": {},
   "source": [
    "Let's create a way to quickly evaluate a model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a67a52c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, roc_auc_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "def evaluate():\n",
    "    print('Precision score is {}'.format(precision_score(y_test,preds, average='macro'))) #use macro scoring since classes are imbalanced\n",
    "    print('Recall score is {}'.format(recall_score(y_test,preds, average='macro'))) #use macro scoring since classes are imbalanced\n",
    "    print('F1 score is {}'.format(f1_score(y_test,preds, average='macro'))) #use macro scoring since classes are imbalanced\n",
    "    print('Accuracy score is {}'.format(accuracy_score(y_test,preds))) \n",
    "    print('ROC_AUC score is {}'.format(roc_auc_score(y_test,preds))) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b170c2",
   "metadata": {},
   "source": [
    "<font color=\"purple\" size=\"4px\"> We will test each dataset on a basic logistic regression model and choose the best dataset for upcoming modelling </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07e4fb9e",
   "metadata": {},
   "source": [
    "First let's try using the cleaned data, without outliers removed, and with all of the features with a basic model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c04d8fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "#let the feature dataframe contain every column of df, except the value we are predicting,Persistency_Flag_Persistent\n",
    "X=df_modified2.loc[:,df_modified2.columns!=\"Persistency_Flag_Persistent\"]\n",
    "#let the target array contain only the value we are predicting, Persistency_Flag_Persistent\n",
    "# y=df.loc[:,df.columns==\"heart_disease\"].values.ravel()\n",
    "y=df_modified2.loc[:,df_modified2.columns==\"Persistency_Flag_Persistent\"].values.ravel()\n",
    "X_train, X_test, y_train, y_test=train_test_split(X,y,test_size=0.30,random_state=123)  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09b7c6b3",
   "metadata": {},
   "source": [
    "Let's create an evaluate a simple logistic regression model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "851f2dd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision score is 0.7986024551463644\n",
      "Recall score is 0.7862341141967486\n",
      "F1 score is 0.7912343536535833\n",
      "Accuracy score is 0.8073929961089494\n",
      "ROC_AUC score is 0.7862341141967486\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg=LogisticRegression(max_iter=1000000)\n",
    "logreg.fit(X_train,y_train)\n",
    "preds=logreg.predict(X_test)\n",
    "evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "085853b5",
   "metadata": {},
   "source": [
    "Let's try again, but with outliers removed and still using all of the features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ac04ee24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision score is 0.7889791368052237\n",
      "Recall score is 0.7561405985319029\n",
      "F1 score is 0.7686945500633713\n",
      "Accuracy score is 0.8136986301369863\n",
      "ROC_AUC score is 0.756140598531903\n"
     ]
    }
   ],
   "source": [
    "X=df_modified.loc[:,df_modified.columns!=\"Persistency_Flag_Persistent\"]\n",
    "y=df_modified.loc[:,df_modified.columns==\"Persistency_Flag_Persistent\"].values.ravel()\n",
    "X_train, X_test, y_train, y_test=train_test_split(X,y,test_size=0.30,random_state=123)   \n",
    "logreg=LogisticRegression(max_iter=1000000)\n",
    "logreg.fit(X_train,y_train)\n",
    "preds=logreg.predict(X_test)\n",
    "evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a72efb3",
   "metadata": {},
   "source": [
    "We used SelectKBest in weeks 8-9 to find the best 6 features. Let's test the dataframe with just the 6 best features and target, and outliers removed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e786dc7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision score is 0.7588480939386422\n",
      "Recall score is 0.7209380293619424\n",
      "F1 score is 0.7340279552186546\n",
      "Accuracy score is 0.7890410958904109\n",
      "ROC_AUC score is 0.7209380293619425\n"
     ]
    }
   ],
   "source": [
    "X=df_best.loc[:,df_best.columns!=\"Persistency_Flag_Persistent\"]\n",
    "y=df_best.loc[:,df_best.columns==\"Persistency_Flag_Persistent\"].values.ravel()\n",
    "X_train, X_test, y_train, y_test=train_test_split(X,y,test_size=0.3,random_state=123)   \n",
    "logreg=LogisticRegression(max_iter=1000000)\n",
    "logreg.fit(X_train,y_train)\n",
    "preds=logreg.predict(X_test)\n",
    "evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efd9c176",
   "metadata": {},
   "source": [
    "Let's test the dataframe with just the 6 best features and target, and outliers included:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "25f60c3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision score is 0.7846142509763466\n",
      "Recall score is 0.7641599382067901\n",
      "F1 score is 0.7712990685296075\n",
      "Accuracy score is 0.791828793774319\n",
      "ROC_AUC score is 0.7641599382067901\n"
     ]
    }
   ],
   "source": [
    "X=df_best2.loc[:,df_best2.columns!=\"Persistency_Flag_Persistent\"]\n",
    "y=df_best2.loc[:,df_best2.columns==\"Persistency_Flag_Persistent\"].values.ravel()\n",
    "X_train, X_test, y_train, y_test=train_test_split(X,y,test_size=0.30,random_state=123) \n",
    "\n",
    "logreg.fit(X_train,y_train)\n",
    "preds=logreg.predict(X_test)\n",
    "evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48bdae0c",
   "metadata": {},
   "source": [
    "The df_best dataset seemed to be the best overall to me, based on the evaluation metrics (e.g., high accuracy), and also, there are only 6 features and lower number of rows, so using this data would be computationally efficient, especially since we will be doing some grid searching.We will use this dataset in all future modelling. Also, only needing 6 features to predict persistency may be very useful for the company."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "01dd404e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dexa_During_Rx_Y</th>\n",
       "      <th>Comorb_Encounter_For_Screening_For_Malignant_Neoplasms_Y</th>\n",
       "      <th>Comorb_Encounter_For_Immunization_Y</th>\n",
       "      <th>Comorb_Encntr_For_General_Exam_W_O_Complaint,_Susp_Or_Reprtd_Dx_Y</th>\n",
       "      <th>Comorb_Long_Term_Current_Drug_Therapy_Y</th>\n",
       "      <th>Concom_Viral_Vaccines_Y</th>\n",
       "      <th>Persistency_Flag_Persistent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Dexa_During_Rx_Y  Comorb_Encounter_For_Screening_For_Malignant_Neoplasms_Y  \\\n",
       "0               0.0                                                1.0          \n",
       "1               0.0                                                0.0          \n",
       "2               0.0                                                0.0          \n",
       "3               0.0                                                0.0          \n",
       "4               0.0                                                1.0          \n",
       "\n",
       "   Comorb_Encounter_For_Immunization_Y  \\\n",
       "0                                  1.0   \n",
       "1                                  0.0   \n",
       "2                                  0.0   \n",
       "3                                  0.0   \n",
       "4                                  0.0   \n",
       "\n",
       "   Comorb_Encntr_For_General_Exam_W_O_Complaint,_Susp_Or_Reprtd_Dx_Y  \\\n",
       "0                                                1.0                   \n",
       "1                                                1.0                   \n",
       "2                                                0.0                   \n",
       "3                                                1.0                   \n",
       "4                                                0.0                   \n",
       "\n",
       "   Comorb_Long_Term_Current_Drug_Therapy_Y  Concom_Viral_Vaccines_Y  \\\n",
       "0                                      1.0                      0.0   \n",
       "1                                      0.0                      0.0   \n",
       "2                                      0.0                      0.0   \n",
       "3                                      0.0                      0.0   \n",
       "4                                      0.0                      0.0   \n",
       "\n",
       "   Persistency_Flag_Persistent  \n",
       "0                          0.0  \n",
       "1                          0.0  \n",
       "2                          0.0  \n",
       "3                          0.0  \n",
       "4                          0.0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_best.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84715ca6",
   "metadata": {},
   "source": [
    "<font color=\"purple\" size=\"4px\"> Now that we have chosen the best dataset to use, let's try to optimise our logistic regression model    </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cea1b26",
   "metadata": {},
   "source": [
    "Let's check the base model's cross-val scores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2bd3faf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores are: [0.94149444 0.78664547 0.89650238 0.83926868 0.89677318 0.85440798\n",
      " 0.84861647 0.80276705 0.85762548 0.85617761]\n",
      "The mean cross-validation score is:0.8580278747345309\n"
     ]
    }
   ],
   "source": [
    "X=df_best.loc[:,df_best.columns!=\"Persistency_Flag_Persistent\"]\n",
    "y=df_best.loc[:,df_best.columns==\"Persistency_Flag_Persistent\"].values.ravel()\n",
    "X_train, X_test, y_train, y_test=train_test_split(X,y,test_size=0.3,random_state=123)  \n",
    "\n",
    "logreg=LogisticRegression(max_iter=1000000)\n",
    "scores = cross_val_score(logreg, X, y, cv=10, scoring='roc_auc')#\n",
    "print('Cross-validation scores are: {}'.format(scores))\n",
    "scores_mean=np.mean(scores)\n",
    "print('The mean cross-validation score is:{}'.format(scores_mean))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "567f793a",
   "metadata": {},
   "source": [
    "It looks like the base model is good at generalising to new data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77107a97",
   "metadata": {},
   "source": [
    "Let's optimise the logistic regression model on df_best (uncomment to run):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0169845e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8742397653194264 LogisticRegression(C=0.1, max_iter=1000000, n_jobs=-1)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "logreg = LogisticRegression(max_iter=1000000,\n",
    "                      n_jobs=-1)\n",
    "\n",
    "params={\"C\":[0.001, 0.01, 0.1, 1, 10, 100, 1000] }\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "skf = StratifiedKFold(n_splits=10, shuffle = False) # make sure class balance in each fold is the same as in the orginal dataset\n",
    "\n",
    "grid_search=GridSearchCV(logreg,params,cv=skf.split(X_train,y_train),scoring='roc_auc')\n",
    "\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "#print(grid_search.cv_results_)\n",
    "print(grid_search.best_score_, grid_search.best_estimator_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97369135",
   "metadata": {},
   "source": [
    "We now have a logistic regression model with optimal parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c9012379",
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_new=LogisticRegression(C=1, max_iter=1000000, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd36cc79",
   "metadata": {},
   "source": [
    "Let's use the best parameters (i.e., the ones yielding the highest average cross-validation score, 0.867) from grid search:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f55a10e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision score is 0.7588480939386422\n",
      "Recall score is 0.7209380293619424\n",
      "F1 score is 0.7340279552186546\n",
      "Accuracy score is 0.7890410958904109\n",
      "ROC_AUC score is 0.7209380293619425\n"
     ]
    }
   ],
   "source": [
    "logreg_new=LogisticRegression(C=1, max_iter=1000000, n_jobs=-1).fit(X_train,y_train)\n",
    "preds=logreg_new.predict(X_test)\n",
    "evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "957ca815",
   "metadata": {},
   "source": [
    "<font color=\"purple\" size=\"4px\"> Let's create an XGB classifier and find the best hyperparameters: </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fe9df11",
   "metadata": {},
   "source": [
    "Let's create an XGB Classifier with mostly default paramters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1f7f619e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xgboost\n",
      "  Downloading xgboost-1.5.2-py3-none-win_amd64.whl (106.6 MB)\n",
      "Requirement already satisfied: scipy in c:\\users\\obiri\\anaconda3\\envs\\main\\lib\\site-packages (from xgboost) (1.7.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\obiri\\anaconda3\\envs\\main\\lib\\site-packages (from xgboost) (1.21.5)\n",
      "Installing collected packages: xgboost\n",
      "Successfully installed xgboost-1.5.2\n"
     ]
    }
   ],
   "source": [
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ef8f9a34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores are: [0.92209857 0.80349762 0.88950715 0.8027027  0.88424185 0.86599099\n",
      " 0.81483269 0.80662806 0.84861647 0.82335907]\n",
      "The mean cross-validation score is:0.8461475180399329\n",
      "Precision score is 0.7713764337851929\n",
      "Recall score is 0.7387951722190853\n",
      "F1 score is 0.7509370822856396\n",
      "Accuracy score is 0.8\n",
      "ROC_AUC score is 0.7387951722190853\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "xgb=XGBClassifier(eval_metric='mlogloss',use_label_encoder=False)\n",
    "xgb.fit(X_train,y_train)\n",
    "\n",
    "#check cross validation scores:\n",
    "\n",
    "scores = cross_val_score(xgb, X, y, cv=10, scoring='roc_auc')#\n",
    "print('Cross-validation scores are: {}'.format(scores))\n",
    "scores_mean=np.mean(scores)\n",
    "print('The mean cross-validation score is:{}'.format(scores_mean))\n",
    "\n",
    "preds=xgb.predict(X_test)\n",
    "evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3bd5ff4",
   "metadata": {},
   "source": [
    "We ran grid searches with various parameters ranges and attempted to find the best set of parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "cc06aaca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 324 candidates, totalling 3240 fits\n",
      "[16:13:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "0.8739745762711865 XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "              colsample_bynode=1, colsample_bytree=0.8,\n",
      "              enable_categorical=False, gamma=2, gpu_id=-1,\n",
      "              importance_type=None, interaction_constraints='',\n",
      "              learning_rate=0.3, max_delta_step=0, max_depth=3,\n",
      "              min_child_weight=5, missing=nan, monotone_constraints='()',\n",
      "              n_estimators=100, n_jobs=-1, num_parallel_tree=1,\n",
      "              predictor='auto', random_state=0, reg_alpha=0, reg_lambda=1,\n",
      "              scale_pos_weight=1, subsample=0.6, tree_method='exact',\n",
      "              use_label_encoder=False, validate_parameters=1, verbosity=None)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "xgb = XGBClassifier(#learning_rate=0.03, \n",
    "     n_estimators=1000, objective='binary:logistic',\n",
    "                      n_jobs=-1, use_label_encoder=False)\n",
    "\n",
    "params = {\n",
    "              'learning_rate':[0.3],\n",
    "              'n_estimators':[50,100], \n",
    "              'min_child_weight': [1, 5, 10],\n",
    "              'gamma': [0, 1, 2],\n",
    "              'subsample': [0.6, 0.8, 1.0],\n",
    "              'colsample_bytree': [0.6, 0.8, 1.0],\n",
    "              'max_depth': [3,4]\n",
    "         }\n",
    "\n",
    "\n",
    "\n",
    "skf = StratifiedKFold(n_splits=10, shuffle = False)\n",
    "\n",
    "grid_search = GridSearchCV(xgb, param_grid=params,  \n",
    "                              scoring='roc_auc', n_jobs=-1, cv=skf.split(X_train,y_train), verbose=3\n",
    "                             )\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "#print(grid_search.cv_results_)\n",
    "\n",
    "print(grid_search.best_score_, grid_search.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73298d02",
   "metadata": {},
   "source": [
    "We shall use the best parameters (those yielding the highest average cross val score(0.870)) from grid search:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4ae2a013",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision score is 0.7770443476031788\n",
      "Recall score is 0.7288431677018633\n",
      "F1 score is 0.7445962137550923\n",
      "Accuracy score is 0.8\n",
      "ROC_AUC score is 0.7288431677018634\n"
     ]
    }
   ],
   "source": [
    "xgb_new=XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
    "              colsample_bynode=1, colsample_bytree=0.8, gamma=2, gpu_id=-1,\n",
    "              importance_type='gain', interaction_constraints='',\n",
    "              learning_rate=0.3, max_delta_step=0, max_depth=4,\n",
    "              min_child_weight=5, #missing=nan,\n",
    "              monotone_constraints='()',\n",
    "              n_estimators=100, n_jobs=-1, num_parallel_tree=1, random_state=0,\n",
    "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=0.6,\n",
    "              tree_method='exact', use_label_encoder=False,\n",
    "              validate_parameters=1, verbosity=None,\n",
    "                     eval_metric='mlogloss' #specify eval metric to avoid warnings \n",
    "                     )\n",
    "\n",
    "xgb_new.fit(X_train,y_train)\n",
    "\n",
    "#test on test data now:\n",
    "preds=xgb_new.predict(X_test)\n",
    "evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b95fa3f6",
   "metadata": {},
   "source": [
    "<font color=\"purple\" size=\"4px\">  Let's create a neural network and optimise its hyperparameters: </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b30e367",
   "metadata": {},
   "source": [
    "Import necessary packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "cf2f6262",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras import metrics\n",
    "import tensorflow\n",
    "from keras.wrappers.scikit_learn import KerasClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b10f9f57",
   "metadata": {},
   "source": [
    "Define the network architecture and wrapper for KerasClassifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "78a2a618",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_nn(optimizer='uniform', init='adam'):\n",
    "    nn = Sequential()\n",
    "    nn.add(Dense(5, input_dim=X_train.shape[1], activation='relu')) #let's use 2/3 size of input layer + size of output layer for number of nodes\n",
    "    nn.add(Dense(5, activation='relu'))\n",
    "    nn.add(Dense(1, activation='relu'))\n",
    "    nn.compile(loss='binary_crossentropy', optimizer='adam', \n",
    "               #metrics='roc-auc'\n",
    "              )\n",
    "    return nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "3094ac30",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Obiri\\AppData\\Local\\Temp/ipykernel_16800/880184467.py:1: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead.\n",
      "  nn=KerasClassifier(build_fn=create_nn, verbose=0)\n"
     ]
    }
   ],
   "source": [
    "nn=KerasClassifier(build_fn=create_nn, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc3e8be4",
   "metadata": {},
   "source": [
    "We used grid search to search for optimal parameters (we used various ranges and narrowed the parameters down). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "34c7d91b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Obiri\\anaconda3\\envs\\main\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [nan nan]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "optimizers = [#'rmsprop',\n",
    "    'adam'\n",
    "]\n",
    "init = [#'glorot_uniform'\n",
    "    #'normal',\n",
    "         'uniform'\n",
    "]\n",
    "epochs = [150]\n",
    "batches = [5,10]\n",
    "\n",
    "params = dict(optimizer=optimizers, epochs=epochs, \n",
    "                  batch_size=batches,\n",
    "                  init=init)\n",
    "\n",
    "skf = StratifiedKFold(n_splits=10, shuffle = False)\n",
    "\n",
    "grid_search = GridSearchCV(estimator=nn, param_grid=params, n_jobs=-1, cv=skf.split(X_train,y_train))\n",
    "grid_search = grid_search.fit(X_train.values, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "351891b5",
   "metadata": {},
   "source": [
    "Let's use the params which acheived the best average cross-validation score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "8623b30c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Obiri\\AppData\\Local\\Temp/ipykernel_16800/4053258494.py:1: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead.\n",
      "  nn_new=KerasClassifier(build_fn=create_nn, verbose=0,batch_size=5, epochs=150, init='uniform', optimizer='adam')\n"
     ]
    }
   ],
   "source": [
    "nn_new=KerasClassifier(build_fn=create_nn, verbose=0,batch_size=5, epochs=150, init='uniform', optimizer='adam')\n",
    "nn_new._estimator_type=\"classifier\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37b26505",
   "metadata": {},
   "source": [
    "Train the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "b42191e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e611164730>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_new.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b24ce34",
   "metadata": {},
   "source": [
    "Predict and evaluate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "071ad4fa",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision score is 0.7629542688228135\n",
      "Recall score is 0.713474025974026\n",
      "F1 score is 0.7288235350874654\n",
      "Accuracy score is 0.7890410958904109\n",
      "ROC_AUC score is 0.7134740259740259\n"
     ]
    }
   ],
   "source": [
    "nn_new.fit(X_train, y_train)\n",
    "preds = nn_new.predict(X_test)\n",
    "evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2e63214",
   "metadata": {},
   "source": [
    "Best: 0.793230 using {'batch_size': 20, 'epochs': 100, 'init': 'uniform', 'optimizer': 'adam'}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b4df652",
   "metadata": {},
   "source": [
    "<font color=\"purple\" size=\"4px\"> Let's create a random forest and find the best hyperparameters: </font>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "506fb418",
   "metadata": {},
   "source": [
    "Let's create a random forest classifier with default settings and check the cross val scores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "4aca9956",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores are: [0.9227345  0.80413355 0.89284579 0.80445151 0.88549499 0.86631274\n",
      " 0.81579794 0.81048906 0.85666023 0.84169884]\n",
      "The mean cross-validation score is:0.8500619145239888\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf=RandomForestClassifier()\n",
    "\n",
    "scores = cross_val_score(rf, X, y, cv=10, scoring='roc_auc')#\n",
    "print('Cross-validation scores are: {}'.format(scores))\n",
    "scores_mean=np.mean(scores)\n",
    "print('The mean cross-validation score is:{}'.format(scores_mean))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccf8fc39",
   "metadata": {},
   "source": [
    "Train, predict and evaluate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "de928908",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision score is 0.7860715178794699\n",
      "Recall score is 0.7422360248447204\n",
      "F1 score is 0.7574428495481127\n",
      "Accuracy score is 0.8082191780821918\n",
      "ROC_AUC score is 0.7422360248447206\n"
     ]
    }
   ],
   "source": [
    "rf.fit(X_train,y_train)\n",
    "preds=rf.predict(X_test)\n",
    "evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "63ce8fc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=11, min_samples_leaf=8, min_samples_split=10,\n",
       "                       n_estimators=1000)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "\n",
    "params= {'bootstrap': [True],\n",
    "  'max_depth': [11],\n",
    "  'max_features': ['auto'],\n",
    "  'min_samples_leaf': [7,8],\n",
    "  'min_samples_split': [9,10],\n",
    "  'n_estimators': [1000]}\n",
    "\n",
    "skf = StratifiedKFold(n_splits=10, shuffle = False)\n",
    "grid_search = GridSearchCV(estimator=rf, param_grid=params, n_jobs=-1, scoring='roc_auc' ,cv=skf.split(X_train,y_train))\n",
    "grid_search = grid_search.fit(X_train, y_train)\n",
    "\n",
    "#print(grid_search.best_score_,grid_search.best_params_)\n",
    "# #print(grid_search.cv_results_)\n",
    "grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19c5ba60",
   "metadata": {},
   "source": [
    "The best average cross-val score was 0.864. Let's use the estimator which achieved this score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "61ca8d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_new=RandomForestClassifier(**{'bootstrap': True, 'max_depth': 11, 'max_features': 'auto', 'min_samples_leaf': 8, 'min_samples_split': 9, 'n_estimators': 1000})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39fe54fd",
   "metadata": {},
   "source": [
    "Train, predict and evaluate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "b97cc546",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision score is 0.7828733766233766\n",
      "Recall score is 0.7213791643139469\n",
      "F1 score is 0.739410654382928\n",
      "Accuracy score is 0.8\n",
      "ROC_AUC score is 0.7213791643139469\n"
     ]
    }
   ],
   "source": [
    "rf_new.fit(X_train,y_train)\n",
    "preds=rf_new.predict(X_test)\n",
    "evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6783877",
   "metadata": {},
   "source": [
    "<font color=\"purple\" size=\"4px\">Let's create a K nearest neighbors classifier and find the best value for K: </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32031c08",
   "metadata": {},
   "source": [
    "Let's define a KNN with default parameters, and check the cross-validation scores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "423b516c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores are: [0.91240064 0.80985692 0.90461049 0.83688394 0.84053885 0.77879665\n",
      " 0.83413771 0.77155727 0.84218147 0.79247104]\n",
      "The mean cross-validation score is:0.8323434978543338\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import  KNeighborsClassifier\n",
    "knn=KNeighborsClassifier()\n",
    "\n",
    "scores = cross_val_score(knn, X, y, cv=10, scoring='roc_auc')#\n",
    "print('Cross-validation scores are: {}'.format(scores))\n",
    "scores_mean=np.mean(scores)\n",
    "print('The mean cross-validation score is:{}'.format(scores_mean))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0112549b",
   "metadata": {},
   "source": [
    "cross-val scores are quite close together, except for the 0.63 score."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48afd3fd",
   "metadata": {},
   "source": [
    "let's train the knn and predict and evaluate on the test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "b31c689d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision score is 0.7695068920249426\n",
      "Recall score is 0.7318428853754941\n",
      "F1 score is 0.7451886792452831\n",
      "Accuracy score is 0.7972602739726027\n",
      "ROC_AUC score is 0.731842885375494\n"
     ]
    }
   ],
   "source": [
    "knn.fit(X_train,y_train)\n",
    "preds=knn.predict(X_test)\n",
    "acc_score=accuracy_score(y_test,preds)\n",
    "evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c51cb277",
   "metadata": {},
   "source": [
    "Let's create a grid search to find the best value of K."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "1e084e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.model_selection import GridSearchCV\n",
    "#from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "#params = {\n",
    "#     'n_neighbors':[n_neigh] \n",
    "#    }\n",
    "\n",
    "#skf = StratifiedKFold(n_splits=10, shuffle = False)\n",
    "#n_neigh=[i for i in range(1,33) if i%2!=0]\n",
    "#grid_search = GridSearchCV(estimator=knn, param_grid=params, n_jobs=-1, scoring='roc_auc' ,cv=skf.split(X_train,y_train))\n",
    "#grid_search = grid_search.fit(X_train, y_train)\n",
    "\n",
    "# print(grid_search.best_score_,grid_search.best_params_)\n",
    "# #print(grid_search.cv_results_)\n",
    "#grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a756421e",
   "metadata": {},
   "source": [
    "let's use the parameters with the highest average cross-val score (0.853) and predict and evalute on the test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "72baf049",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision score is 0.7695068920249426\n",
      "Recall score is 0.7318428853754941\n",
      "F1 score is 0.7451886792452831\n",
      "Accuracy score is 0.7972602739726027\n",
      "ROC_AUC score is 0.731842885375494\n"
     ]
    }
   ],
   "source": [
    "knn_new=KNeighborsClassifier(n_neighbors=31)\n",
    "preds=knn.predict(X_test)\n",
    "evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0c90453",
   "metadata": {},
   "source": [
    "<font color=\"purple\" size=\"4px\">Let's use stacking: </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0883619c",
   "metadata": {},
   "source": [
    "Let's use the top 3 estimators (from the code blocks above):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "e446b54a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Obiri\\AppData\\Local\\Temp/ipykernel_16800/2579518805.py:14: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead.\n",
      "  nn_new=KerasClassifier(build_fn=create_nn, verbose=0,batch_size=5, epochs=150, init='uniform', optimizer='adam')\n"
     ]
    }
   ],
   "source": [
    "xgb_new=XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
    "              colsample_bynode=1, colsample_bytree=0.8, gamma=2, gpu_id=-1,\n",
    "              importance_type='gain', interaction_constraints='',\n",
    "              learning_rate=0.3, max_delta_step=0, max_depth=4,\n",
    "              min_child_weight=5, #missing=nan,\n",
    "              monotone_constraints='()',\n",
    "              n_estimators=100, n_jobs=-1, num_parallel_tree=1, random_state=0,\n",
    "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=0.6,\n",
    "              tree_method='exact', use_label_encoder=False,\n",
    "              validate_parameters=1, verbosity=None,\n",
    "                     eval_metric='mlogloss' #specify eval metric to avoid warnings \n",
    "                     )\n",
    "\n",
    "nn_new=KerasClassifier(build_fn=create_nn, verbose=0,batch_size=5, epochs=150, init='uniform', optimizer='adam')\n",
    "nn_new._estimator_type=\"classifier\"\n",
    "\n",
    "rf_new=RandomForestClassifier(**{'bootstrap': True, 'max_depth': 11, 'max_features': 'auto', 'min_samples_leaf': 8, 'min_samples_split': 9, 'n_estimators': 1000})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d69bc9bd",
   "metadata": {},
   "source": [
    "Define the splitting method and declare the estimators:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "afb14f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "skf = StratifiedKFold(n_splits=10, shuffle = False)\n",
    "estimators=[('xgb_new', xgb_new), ('nn_new', nn_new), ('rf_new',rf_new)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13951f34",
   "metadata": {},
   "source": [
    "Define the stacking model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "5fa56e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StackingClassifier(\n",
    "    estimators=estimators,\n",
    "    cv=skf.split(X_train,y_train))    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b6f6bca",
   "metadata": {},
   "source": [
    "Fit to the training data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "c9bdb87a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StackingClassifier(cv=<generator object _BaseKFold.split at 0x000001E6124E6510>,\n",
       "                   estimators=[('xgb_new',\n",
       "                                XGBClassifier(base_score=0.5, booster='gbtree',\n",
       "                                              colsample_bylevel=1,\n",
       "                                              colsample_bynode=1,\n",
       "                                              colsample_bytree=0.8,\n",
       "                                              enable_categorical=False,\n",
       "                                              eval_metric='mlogloss', gamma=2,\n",
       "                                              gpu_id=-1, importance_type='gain',\n",
       "                                              interaction_constraints='',\n",
       "                                              learning_rate=0.3,\n",
       "                                              max_delta_s...\n",
       "                                              predictor=None, random_state=0,\n",
       "                                              reg_alpha=0, reg_lambda=1,\n",
       "                                              scale_pos_weight=1, subsample=0.6,\n",
       "                                              tree_method='exact',\n",
       "                                              use_label_encoder=False,\n",
       "                                              validate_parameters=1,\n",
       "                                              verbosity=None)),\n",
       "                               ('nn_new',\n",
       "                                <keras.wrappers.scikit_learn.KerasClassifier object at 0x000001E61497D370>),\n",
       "                               ('rf_new',\n",
       "                                RandomForestClassifier(max_depth=11,\n",
       "                                                       min_samples_leaf=8,\n",
       "                                                       min_samples_split=9,\n",
       "                                                       n_estimators=1000))])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35f8b3da",
   "metadata": {},
   "source": [
    "Predict and evaluate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "0d56526b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision score is 0.76460564751704\n",
      "Recall score is 0.7109860248447204\n",
      "F1 score is 0.7270007479431564\n",
      "Accuracy score is 0.7890410958904109\n",
      "ROC_AUC score is 0.7109860248447205\n"
     ]
    }
   ],
   "source": [
    "preds=sc.predict(X_test)\n",
    "evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c93b1164",
   "metadata": {},
   "source": [
    "<font color=\"purple\" size=\"4px\">Let's use voting: </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a9185ca",
   "metadata": {},
   "source": [
    "Let's define the voting classifier model. The neural network performed well so we will give it a relatively high weight:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "61d9dc30",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "vc = VotingClassifier(estimators= [('xgb_new', xgb_new),\n",
    "                                   ('nn_new', nn_new), \n",
    "                                   ('rf_new',rf_new)], \n",
    "                      voting='soft', #vote based on probabilities rather than majority vote of classes\n",
    "                      weights=[1,2,1] #assign weights: xgboost performed very well so we'll give it a relatively high weight\n",
    "                     )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dcc9747",
   "metadata": {},
   "source": [
    "Train the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "b9668227",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('xgb_new',\n",
       "                              XGBClassifier(base_score=0.5, booster='gbtree',\n",
       "                                            colsample_bylevel=1,\n",
       "                                            colsample_bynode=1,\n",
       "                                            colsample_bytree=0.8,\n",
       "                                            enable_categorical=False,\n",
       "                                            eval_metric='mlogloss', gamma=2,\n",
       "                                            gpu_id=-1, importance_type='gain',\n",
       "                                            interaction_constraints='',\n",
       "                                            learning_rate=0.3, max_delta_step=0,\n",
       "                                            max_depth=4, min_child_weight=5,\n",
       "                                            missing=nan,\n",
       "                                            monotone_c...\n",
       "                                            random_state=0, reg_alpha=0,\n",
       "                                            reg_lambda=1, scale_pos_weight=1,\n",
       "                                            subsample=0.6, tree_method='exact',\n",
       "                                            use_label_encoder=False,\n",
       "                                            validate_parameters=1,\n",
       "                                            verbosity=None)),\n",
       "                             ('nn_new',\n",
       "                              <keras.wrappers.scikit_learn.KerasClassifier object at 0x000001E61497D370>),\n",
       "                             ('rf_new',\n",
       "                              RandomForestClassifier(max_depth=11,\n",
       "                                                     min_samples_leaf=8,\n",
       "                                                     min_samples_split=9,\n",
       "                                                     n_estimators=1000))],\n",
       "                 voting='soft', weights=[1, 2, 1])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vc.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93f88be5",
   "metadata": {},
   "source": [
    "Predict and evaluate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "8c6f73fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision score is 0.34657534246575344\n",
      "Recall score is 0.5\n",
      "F1 score is 0.40938511326860844\n",
      "Accuracy score is 0.6931506849315069\n",
      "ROC_AUC score is 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Obiri\\anaconda3\\envs\\main\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "preds=vc.predict(X_test)\n",
    "evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9018e0e7",
   "metadata": {},
   "source": [
    "<font color=\"green\" size=\"4px\">Which model is best? </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "275ce739",
   "metadata": {},
   "source": [
    "The XGB classifier (xgb_new) was definitely a good model, with solid scores overall, and some relatively high precision and recall scores. The default model for xgb boost had a good cross-validation score and this wasn't found to change significantly after parameter tuning.  The neural network (nn_new) performed slightly better (or the same) compared to xgb_new in general. The random forest (rf_new) also performed well but was slighly worse than the other models. Both the voting classifer (vc) and stacking classifer (sc) performed well in general but weren't better than nn_new. Overall the best model is nn_new."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63e7a536",
   "metadata": {},
   "source": [
    "These are the evaluation metrics for nn_new on the test data when I ran the code (we found these earlier):    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "05ffa3c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision score 0.8175742386268702\n",
      "Recall score is 0.777711363485422\n",
      "F1 score is 0.7911991199119912\n",
      "Accuracy score is 0.821917808219178\n",
      "ROC_AUC score is 0.777711363485422\n"
     ]
    }
   ],
   "source": [
    "print(\"Precision score 0.8175742386268702\")\n",
    "print(\"Recall score is 0.777711363485422\")\n",
    "print(\"F1 score is 0.7911991199119912\")\n",
    "print(\"Accuracy score is 0.821917808219178\")\n",
    "print(\"ROC_AUC score is 0.777711363485422\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6a697e6",
   "metadata": {},
   "source": [
    "Save the best model to json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "05030d9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "# Convert model to JSON\n",
    "model_json = nn_new.model.to_json()\n",
    "with open(\"neural_network_best_model.json\",\"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "#Save weights to HDF5\n",
    "nn_new.model.save_weights(\"neural_network_best_model.h5\",overwrite=True)\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d0d24e1",
   "metadata": {},
   "source": [
    "Read the model and re-evaluate it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "abc29535",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n",
      "accuracy: 78.90%\n"
     ]
    }
   ],
   "source": [
    "# load json and create model\n",
    "json_file = open('neural_network_best_model.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(\"neural_network_best_model.h5\")\n",
    "print(\"Loaded model from disk\")\n",
    " \n",
    "# evaluate loaded model on test data\n",
    "loaded_model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "score = loaded_model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"%s: %.2f%%\" % (loaded_model.metrics_names[1], score[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15785294",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
